# ü¶Ö Bielik 11B ‚Üí Amazon Bedrock

> **Jeden command. Zero lokalnej konfiguracji. Polski model AI w chmurze AWS.**

Automatyczny import [Bielik-11B-v3.0-Instruct](https://huggingface.co/speakleash/Bielik-11B-v3.0-Instruct) (projekt [SpeakLeash](https://speakleash.org)) do Amazon Bedrock przez AWS CloudShell ‚Äî bez instalowania czegokolwiek na swoim komputerze.

üì∫ **Tutorial na YouTube:** [youtube.com/@livinginacloud](https://www.youtube.com/@livinginacloud)  
üìù **Blog post:** [poznajaws.pl](https://poznajaws.pl)

---

## ‚ö° TL;DR ‚Äî Uruchomienie

Otw√≥rz **[AWS CloudShell](https://console.aws.amazon.com/cloudshell)** i wklej:

```bash
bash <(curl -fsSL https://raw.githubusercontent.com/donkoyote/bielik-bedrock-import/main/deploy.sh)
```

Skrypt zapyta tylko o token HuggingFace ‚Äî resztƒÖ zajmie siƒô sam.

---

## Co siƒô dzieje pod spodem?

```
CloudShell (Ty wklejasz 1 komendƒô)
    ‚îÇ
    ‚îú‚îÄ 1. Pobiera szablon CloudFormation z tego repo
    ‚îú‚îÄ 2. Tworzy infrastrukturƒô AWS (~2 min):
    ‚îÇ       ‚îú‚îÄ‚îÄ S3 Bucket          (pliki modelu ~22 GB)
    ‚îÇ       ‚îú‚îÄ‚îÄ IAM Role CodeBuild
    ‚îÇ       ‚îú‚îÄ‚îÄ IAM Role Bedrock
    ‚îÇ       ‚îú‚îÄ‚îÄ SSM Parameter      (HuggingFace token ‚Äî bezpiecznie)
    ‚îÇ       ‚îî‚îÄ‚îÄ CodeBuild Project
    ‚îî‚îÄ 3. Uruchamia CodeBuild, kt√≥ry:
            ‚îú‚îÄ‚îÄ [install]     pip install huggingface_hub
            ‚îú‚îÄ‚îÄ [pre_build]   pobiera token z SSM
            ‚îú‚îÄ‚îÄ [build]       snapshot_download ‚Üí aws s3 sync (~22 GB)
            ‚îî‚îÄ‚îÄ [post_build]  bedrock.create_model_import_job + polling
```

**Szacowany czas:** 35‚Äì55 minut (g≈Ç√≥wnie transfer danych)  
**Szacowany koszt jednorazowy:** ~$0.95‚Äì1.40 ¬∑ **Storage:** ~$0.54/mies ¬∑ **Inference:** pay-per-use

üëâ Szczeg√≥≈Çowy breakdown koszt√≥w: [sekcja Koszty infrastruktury](#koszty-infrastruktury--eu-central-1)

---

## Wymagania

- Konto AWS z uprawnieniami: `CloudFormation`, `S3`, `IAM`, `CodeBuild`, `Bedrock`, `SSM`
- Konto [HuggingFace](https://huggingface.co) ‚Äî darmowe
- Zaakceptowane warunki modelu: [speakleash/Bielik-11B-v3.0-Instruct](https://huggingface.co/speakleash/Bielik-11B-v3.0-Instruct) *(kliknij "Agree" na stronie)*
- Token HuggingFace z uprawnieniem `read` ‚Üí [wygeneruj tutaj](https://huggingface.co/settings/tokens)

> **Wspierane regiony:** `eu-central-1` ‚úÖ `us-east-1` ‚úÖ `us-east-2` ‚úÖ `us-west-2` ‚úÖ  
> Bedrock Custom Model Import nie jest dostƒôpny we wszystkich regionach.

---

## Monitorowanie importu

Po uruchomieniu `deploy.sh` skrypt wypisze gotowe komendy. Mo≈ºesz te≈º u≈ºyƒá:

```bash
# Logi CodeBuild na ≈ºywo
aws logs tail /aws/codebuild/LIAC-Bielik-Import --follow --region us-east-1

# Status modelu w Bedrock
aws bedrock list-imported-models \
  --region us-east-1 \
  --query 'modelSummaries[*].{Name:modelName,Status:modelStatus}' \
  --output table
```

---

## Testowanie modelu po imporcie

> **Wa≈ºne:** Custom Imported Models nie obs≈ÇugujƒÖ `converse` API. Nale≈ºy u≈ºywaƒá `invoke_model` z formatem promptu zgodnym z Llama 3 Instruct.

```python
import boto3, json

bedrock   = boto3.client("bedrock",         region_name="us-east-1")
runtime   = boto3.client("bedrock-runtime", region_name="us-east-1")

# Pobierz ARN zaimportowanego modelu
models    = bedrock.list_imported_models()
model_arn = next(
    m["modelArn"] for m in models["modelSummaries"]
    if "Bielik" in m["modelName"]
)
print("Model ARN:", model_arn)

# Format promptu Llama 3 Instruct
prompt = """<|begin_of_text|><|start_header_id|>user<|end_header_id|>
Wyja≈õnij mi w 3 zdaniach, czym jest Amazon Bedrock.<|eot_id|>
<|start_header_id|>assistant<|end_header_id|>
"""

response = runtime.invoke_model(
    modelId=model_arn,
    contentType="application/json",
    accept="application/json",
    body=json.dumps({
        "prompt": prompt,
        "max_gen_len": 512,
        "temperature": 0.7,
        "top_p": 0.9,
    })
)

result = json.loads(response["body"].read())
print(result["generation"])
```

**Funkcja pomocnicza do wielokrotnego u≈ºycia:**

```python
import boto3, json

def zapytaj_bielika(pytanie: str, max_tokenow: int = 512) -> str:
    bedrock = boto3.client("bedrock",         region_name="us-east-1")
    runtime = boto3.client("bedrock-runtime", region_name="us-east-1")

    models    = bedrock.list_imported_models()
    model_arn = next(
        m["modelArn"] for m in models["modelSummaries"]
        if "Bielik" in m["modelName"]
    )

    prompt = (
        "<|begin_of_text|>"
        "<|start_header_id|>user<|end_header_id|>\n"
        f"{pytanie}<|eot_id|>\n"
        "<|start_header_id|>assistant<|end_header_id|>\n"
    )

    resp = runtime.invoke_model(
        modelId=model_arn,
        contentType="application/json",
        accept="application/json",
        body=json.dumps({
            "prompt": prompt,
            "max_gen_len": max_tokenow,
            "temperature": 0.7,
            "top_p": 0.9,
        })
    )
    return json.loads(resp["body"].read())["generation"]


# U≈ºycie
print(zapytaj_bielika("Czym jest Amazon S3? Odpowiedz kr√≥tko."))
```

**Szybki test czy model rozumie po polsku** ‚Äî zadaj pytanie wymagajƒÖce wiedzy historycznej:

```python
odpowiedz = zapytaj_bielika(
    "Podaj dotychczasowe miasta, bƒôdƒÖce stolicƒÖ Polski."
)
print(odpowiedz)
```

Poprawna odpowied≈∫ powinna wymieniƒá: **Gniezno** (pierwsza historyczna stolica), **Krak√≥w** (od ok. X w. do 1596 r.) i **Warszawa** (od 1596 r. do dzi≈õ). Je≈õli model odpowiada p≈Çynnie po polsku i zna historiƒô ‚Äî dzia≈Ça poprawnie. ‚úÖ


---

## üóëÔ∏è Cleanup ‚Äî usuwanie zasob√≥w

Otw√≥rz **[AWS CloudShell](https://console.aws.amazon.com/cloudshell)** i wklej:

```bash
bash <(curl -fsSL https://raw.githubusercontent.com/donkoyote/bielik-bedrock-import/main/cleanup.sh)
```

Skrypt pyta o potwierdzenie i usuwa kolejno:

1. **S3 bucket** ‚Äî pliki modelu (~22 GB)
2. **CloudWatch Logs** ‚Äî log group z build√≥w CodeBuild
3. **Stack CloudFormation** ‚Äî CodeBuild Project, IAM Roles, SSM Parameter
4. **Model w Bedrock** *(opcjonalnie, pyta osobno)*

Po cleanup nie pozostajƒÖ ≈ºadne zasoby generujƒÖce koszty.

---

## Struktura repozytorium

```
bielik-bedrock-import/
‚îú‚îÄ‚îÄ deploy.sh                          # ‚Üê g≈Ç√≥wny skrypt (1 komenda w CloudShell)
‚îú‚îÄ‚îÄ cleanup.sh                         # usuwanie zasob√≥w
‚îú‚îÄ‚îÄ cloudformation/
‚îÇ   ‚îî‚îÄ‚îÄ bielik-bedrock-import.yaml    # infrastruktura + buildspec inline
‚îî‚îÄ‚îÄ README.md
```

---

## Parametry CFN (opcjonalne nadpisanie)

Skrypt `deploy.sh` u≈ºywa domy≈õlnych warto≈õci. Je≈õli chcesz dostosowaƒá, mo≈ºesz rƒôcznie wywo≈Çaƒá CFN:

```bash
aws cloudformation deploy \
  --template-file cloudformation/bielik-bedrock-import.yaml \
  --stack-name bielik-bedrock-import \
  --region us-east-1 \
  --capabilities CAPABILITY_NAMED_IAM \
  --parameter-overrides \
    HuggingFaceToken="hf_TWOJ_TOKEN" \
    BedrockModelName="Bielik-11B-v3-Instruct" \
    S3Prefix="bielik-11b-v3" \
    ModelId="speakleash/Bielik-11B-v3.0-Instruct"
```

---

## Koszty infrastruktury ‚Äî eu-central-1

> Wszystkie ceny w USD dla regionu **EU (Frankfurt) eu-central-1**, stan na luty 2026.  
> Weryfikuj aktualne stawki: [aws.amazon.com/bedrock/pricing](https://aws.amazon.com/bedrock/pricing/) ¬∑ [aws.amazon.com/codebuild/pricing](https://aws.amazon.com/codebuild/pricing/)

### üí∏ Jednorazowy koszt wdro≈ºenia

| Us≈Çuga | Zas√≥b | Stawka eu-central-1 | Zu≈ºycie | Koszt |
|--------|-------|---------------------|---------|-------|
| **CloudFormation** | Stack deploy | $0 | ‚Äî | **$0.00** |
| **IAM** | Role, Policy | $0 | ‚Äî | **$0.00** |
| **SSM Parameter Store** | 1 Standard Parameter | $0 | ‚Äî | **$0.00** |
| **CodeBuild** | `BUILD_GENERAL1_LARGE` (Linux) | $0.020/min | ~45 min | **~$0.90** |
| **S3** | Upload 22 GB z CodeBuild ‚Üí S3 | $0 (intra-region transfer) | 22 GB | **$0.00** |
| **S3 PUT requests** | ~10 000 request√≥w | $0.0055/1000 | 10k | **~$0.06** |
| **CloudWatch Logs** | Logi buildu ~50 MB | Free tier: 5 GB/mies | <1 GB | **$0.00** |
| **Bedrock** | Import modelu (jednorazowy job) | $0 (import jest bezp≈Çatny) | ‚Äî | **$0.00** |
| | | | **RAZEM** | **~$0.96** |

> **Uwaga dot. CodeBuild:** AWS nie publikuje osobnych tabel cen per-region dla CodeBuild ‚Äî stosuje jednƒÖ globalnƒÖ stawkƒô. Stawka `general1.large` to **$0.020/min** (Linux). Potwierd≈∫ aktualnƒÖ warto≈õƒá w [AWS Pricing Calculator](https://calculator.aws/).

---

### üì¶ Miesiƒôczny koszt utrzymania (storage)

| Us≈Çuga | Zas√≥b | Stawka eu-central-1 | Ilo≈õƒá | Koszt/mies |
|--------|-------|---------------------|-------|------------|
| **S3 Standard** | Pliki modelu | $0.0245/GB | 22 GB | **~$0.54** |
| **SSM Parameter Store** | Standard Parameter (HF token) | $0 | 1 | **$0.00** |
| **CloudWatch Logs** | Retencja log√≥w buildu | $0.03/GB | ~0.05 GB | **~$0.00** |
| **CodeBuild Project** | Sam projekt (bez build√≥w) | $0 | ‚Äî | **$0.00** |
| | | | **RAZEM** | **~$0.54/mies** |

> üí° Je≈õli model jest ju≈º zaimportowany i bucket S3 nie jest potrzebny, mo≈ºesz go usunƒÖƒá poleceniem `./cleanup.sh`. Oszczƒôdza ~$0.54/mies, ale utracisz mo≈ºliwo≈õƒá re-importu bez ponownego downloadu.

---

### ü§ñ Koszt inference (u≈ºywanie modelu)

Custom Model Import w Bedrock rozlicza siƒô inaczej ni≈º foundation models ‚Äî nie p≈Çacisz za tokeny, lecz za **czas aktywno≈õci kopii modelu** w oknach 5-minutowych.

| Sk≈Çadnik | Szczeg√≥≈Çy |
|----------|-----------|
| **Import modelu** | **$0** ‚Äî bezp≈Çatny |
| **Model storage w Bedrock** | **$0** ‚Äî pliki zostajƒÖ w Twoim S3, Bedrock nie kopiuje |
| **Inference billing** | CMU (Custom Model Unit) √ó czas √ó stawka/CMU/min |
| **Okno rozliczeniowe** | 5 minut od pierwszego wywo≈Çania |
| **Bielik 11B ‚âà CMU** | ~2‚Äì3 CMU (zale≈ºy od wersji hardware przydzielonej przez Bedrock) |
| **Stawka CMU** | Sprawd≈∫ na stronie Bedrock ‚Üí Custom Model Import ‚Üí Tw√≥j model ‚Üí `GetImportedModel` |

**Przyk≈Çadowe wyliczenie** (orientacyjne, dla CMU v1 w eu-central-1):

```
1 zapytanie testowe (~5 min aktywno≈õci):
  2 CMU √ó $0.0021/CMU/min √ó 5 min = ~$0.02

100 zapyta≈Ñ dziennie (model aktywny ~2h):
  2 CMU √ó $0.0021/CMU/min √ó 120 min = ~$0.50/dzie≈Ñ = ~$15/mies
```

> **Jak sprawdziƒá dok≈ÇadnƒÖ stawkƒô CMU dla Twojego modelu:**
> ```bash
> aws bedrock get-imported-model \
>   --model-identifier "arn:aws:bedrock:eu-central-1:ACCOUNT:imported-model/MODEL_ID" \
>   --region eu-central-1 \
>   --query '{CMU: customModelUnitsPerModelCopy, Version: customModelUnitsVersion}'
> ```
> Nastƒôpnie sprawd≈∫ stawkƒô dla tej wersji na [stronie cennika Bedrock](https://aws.amazon.com/bedrock/pricing/) ‚Üí sekcja "Custom Model Import".

---

### üìä Podsumowanie

| Scenariusz | Koszt |
|------------|-------|
| **Jednorazowy deploy** | ~$0.96 |
| **S3 storage/mies (je≈õli zachowujesz bucket)** | ~$0.54 |
| **Test (kilka zapyta≈Ñ)** | ~$0.02‚Äì$0.10 |
| **Produkcja light (100 req/dzie≈Ñ)** | ~$15‚Äì$20/mies |
| **Cleanup (usu≈Ñ bucket po imporcie)** | $0 ongoing |

---

## FAQ

### üî¥ B≈ÇƒÖd: `GatedRepoError: 403 Forbidden` podczas pobierania modelu

To najczƒôstszy problem przy pierwszym uruchomieniu. Model Bielik jest **gated** ‚Äî HuggingFace wymaga jednorazowej akceptacji warunk√≥w zanim token zadzia≈Ça.

**RozwiƒÖzanie:**
1. Wejd≈∫ na [https://huggingface.co/speakleash/Bielik-11B-v3.0-Instruct](https://huggingface.co/speakleash/Bielik-11B-v3.0-Instruct)
2. Kliknij **"Agree and access repository"** (przycisk pojawia siƒô po zalogowaniu)
3. Zaktualizuj token w SSM je≈õli build ju≈º siƒô wywali≈Ç:
```bash
aws ssm put-parameter \
  --name "/bielik-bedrock/hf-token" \
  --value "hf_TWOJ_TOKEN" \
  --type String \
  --overwrite \
  --region us-east-1
```
4. Odpal build ponownie:
```bash
aws codebuild start-build --project-name LIAC-Bielik-Import --region us-east-1
```

> **Uwaga:** Samo posiadanie tokenu HuggingFace nie wystarczy. Akceptacja warunk√≥w i token to dwie niezale≈ºne rzeczy.

---

### ‚ùì Dlaczego CloudShell a nie lokalny terminal?

Zero konfiguracji. Nie musisz instalowaƒá AWS CLI, Pythona ani ≈ºadnych zale≈ºno≈õci. CloudShell ma je wszystkie wbudowane i ju≈º wie o Twoim koncie AWS.

### ‚ùì Czy moje dane sƒÖ bezpieczne?

Token HuggingFace jest przechowywany w AWS SSM Parameter Store, nie w zmiennych ≈õrodowiskowych ani logach. CodeBuild pobiera go dynamicznie tylko na czas wykonania.

### ‚ùì Ile miejsca zajmuje model w S3?

~22 GB (5 plik√≥w safetensors). Koszt S3 to ~$0.50/miesiƒÖc.

### ‚ùì Jak d≈Çugo trwa ca≈Çy proces?

Zwykle 35‚Äì55 minut: ~20 min download z HuggingFace, ~10 min sync do S3, ~15 min import w Bedrock.

### üî¥ B≈ÇƒÖd: `ValidationException: This action doesn't support the model`

Pr√≥bujesz wywo≈Çaƒá model przez `converse` API ‚Äî to API **nie obs≈Çuguje Custom Imported Models**. Dotyczy tylko modeli natywnie dostƒôpnych w Bedrock (Anthropic, Meta, Mistral itp.).

**RozwiƒÖzanie ‚Äî u≈ºyj `invoke_model` zamiast `converse`:**

```python
# ‚ùå NIE DZIA≈ÅA dla custom imported models
client.converse(modelId=model_arn, messages=[...])

# ‚úÖ DZIA≈ÅA
runtime.invoke_model(
    modelId=model_arn,
    contentType="application/json",
    accept="application/json",
    body=json.dumps({
        "prompt": "<|begin_of_text|><|start_header_id|>user<|end_header_id|>\nTwoje pytanie<|eot_id|>\n<|start_header_id|>assistant<|end_header_id|>\n",
        "max_gen_len": 512,
        "temperature": 0.7,
    })
)
```

Pe≈Çny przyk≈Çad z funkcjƒÖ pomocniczƒÖ znajdziesz w sekcji [Testowanie modelu po imporcie](#testowanie-modelu-po-imporcie).

---

### üî¥ B≈ÇƒÖd: `could not find the expected file config.json` w Bedrock

Bedrock dosta≈Ç S3 URI ale nie znalaz≈Ç kompletnego modelu. Najczƒôstsza przyczyna: poprzedni build wywali≈Ç siƒô w trakcie downloadu (np. b≈ÇƒÖd 403) i wgra≈Ç do S3 tylko kilka ma≈Çych plik√≥w ‚Äî bez wag modelu (`.safetensors`).

**Sprawd≈∫ co jest w S3:**
```bash
aws s3 ls s3://TWOJ-BUCKET/bielik-11b-v3/ --recursive --human-readable
```
Powinno byƒá 5 plik√≥w `.safetensors` ≈ÇƒÖcznie ~22 GB. Je≈õli ich nie ma ‚Äî prefix jest niekompletny.

**RozwiƒÖzanie ‚Äî wyczy≈õƒá i odpal od nowa:**
```bash
# Wyczy≈õƒá niekompletny prefix
aws s3 rm s3://TWOJ-BUCKET/bielik-11b-v3/ --recursive

# Odpal nowy build (pobierze i wgra od zera)
aws codebuild start-build --project-name LIAC-Bielik-Import --region us-east-1
```

> Skrypt od wersji z tym fix-em automatycznie sprawdza liczbƒô plik√≥w `.safetensors` przed wywo≈Çaniem Bedrocka i failuje wcze≈õniej z czytelnym komunikatem.

---

### ‚ùì Build siƒô wysypa≈Ç ‚Äî jak sprawdziƒá co posz≈Ço nie tak?

```bash
# Logi na ≈ºywo
aws logs tail /aws/codebuild/LIAC-Bielik-Import --follow --region us-east-1

# Ostatni build i jego status
aws codebuild list-builds-for-project \
  --project-name LIAC-Bielik-Import \
  --region us-east-1 \
  --query 'ids[0]' --output text | \
  xargs -I{} aws codebuild batch-get-builds --ids {} \
  --query 'builds[0].{Status:buildStatus,Phase:currentPhase,Reason:phases[-1].contexts[-1].message}' \
  --output table --region us-east-1
```

Najczƒôstsze przyczyny b≈Çƒôd√≥w:

| B≈ÇƒÖd | Przyczyna | RozwiƒÖzanie |
|------|-----------|-------------|
| `GatedRepoError: 403` | Brak akceptacji warunk√≥w modelu | Kliknij "Agree" na stronie HuggingFace |
| `could not find config.json` | Niekompletny upload do S3 (brak `.safetensors`) | Wyczy≈õƒá prefix S3 i odpal build od nowa |
| `ValidationException: doesn't support the model` | U≈ºycie `converse` zamiast `invoke_model` | Zamie≈Ñ API ‚Äî custom models wymagajƒÖ `invoke_model` |
| `YAML_FILE_ERROR` | Problem z buildspec | Zaktualizuj deploy.sh z repo |
| `Bedrock import Failed` | Z≈Çe pliki modelu lub brak uprawnie≈Ñ IAM | Sprawd≈∫ logi Bedrock i IAM Role |
| `No space left on device` | Za ma≈Ço miejsca na dysku | Zmie≈Ñ `ComputeType` na `BUILD_GENERAL1_2XLARGE` |

### ‚ùì Czy mogƒô uruchomiƒá import jeszcze raz bez re-deployu CFN?

Tak. Stack CFN tworzy infrastrukturƒô raz. Build mo≈ºesz odpalaƒá wielokrotnie:
```bash
aws codebuild start-build --project-name LIAC-Bielik-Import --region us-east-1
```

### ‚ùì W jakich regionach dzia≈Ça Bedrock Custom Model Import?

Aktualnie: `eu-central-1`, `us-east-1`, `us-east-2`, `us-west-2`. Pe≈Çna lista w [dokumentacji AWS](https://docs.aws.amazon.com/bedrock/latest/userguide/custom-model-supported.html).

---

## O projekcie Bielik

[Bielik](https://speakleash.org) to polski model jƒôzykowy tworzony przez spo≈Çeczno≈õƒá [SpeakLeash](https://speakleash.org). Licencja Apache 2.0 ‚Äî mo≈ºesz u≈ºywaƒá komercyjnie.

---

*Materia≈Ç przygotowany przez [poznajaws.pl](https://poznajaws.pl)*  
*Znalaz≈Çe≈õ b≈ÇƒÖd? Otw√≥rz [issue](https://github.com/donkoyote/bielik-bedrock-import/issues) lub PR!*
